{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Libararies Quick Start\n",
    "\n",
    "ref: https://docs.ray.io/en/latest/ray-overview/index.html#ray-libraries-quick-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ray Data: Creating and Transfroming Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 15:41:16,109\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "# Create a Dataset of Python objects.\n",
    "ds = ray.data.range(10000)\n",
    "# -> Dataset(num_blocks=200, num_rows=10000, schema=<class 'int'>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=20, num_rows=10000, schema=<class 'int'>)\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset from Python objects, which are held as Arrow records.\n",
    "ds = ray.data.from_items([\n",
    "        {\"sepal.length\": 5.1, \"sepal.width\": 3.5,\n",
    "         \"petal.length\": 1.4, \"petal.width\": 0.2, \"variety\": \"Setosa\"},\n",
    "        {\"sepal.length\": 4.9, \"sepal.width\": 3.0,\n",
    "         \"petal.length\": 1.4, \"petal.width\": 0.2, \"variety\": \"Setosa\"},\n",
    "        {\"sepal.length\": 4.7, \"sepal.width\": 3.2,\n",
    "         \"petal.length\": 1.3, \"petal.width\": 0.2, \"variety\": \"Setosa\"},\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=3, num_rows=3, schema={sepal.length: double, sepal.width: double, petal.length: double, petal.width: double, variety: string})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sepal.length': 5.1, 'sepal.width': 3.5, 'petal.length': 1.4, 'petal.width': 0.2, 'variety': 'Setosa'}\n",
      "{'sepal.length': 4.9, 'sepal.width': 3.0, 'petal.length': 1.4, 'petal.width': 0.2, 'variety': 'Setosa'}\n",
      "{'sepal.length': 4.7, 'sepal.width': 3.2, 'petal.length': 1.3, 'petal.width': 0.2, 'variety': 'Setosa'}\n"
     ]
    }
   ],
   "source": [
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal.length: double\n",
       "sepal.width: double\n",
       "petal.length: double\n",
       "petal.width: double\n",
       "variety: string"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 15:45:12,853\tWARNING read_api.py:326 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    }
   ],
   "source": [
    "# Create from CSV.\n",
    "# Tip: \"example://\" is a convenient protocol to access the\n",
    "# python/ray/data/examples/data directory.\n",
    "ds = ray.data.read_csv(\"example://iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=1, num_rows=150, schema={sepal.length: double, sepal.width: double, petal.length: double, petal.width: double, variety: string})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArrowRow({'sepal.length': 5.1,\n",
       "           'sepal.width': 3.5,\n",
       "           'petal.length': 1.4,\n",
       "           'petal.width': 0.2,\n",
       "           'variety': 'Setosa'}),\n",
       " ArrowRow({'sepal.length': 4.9,\n",
       "           'sepal.width': 3.0,\n",
       "           'petal.length': 1.4,\n",
       "           'petal.width': 0.2,\n",
       "           'variety': 'Setosa'}),\n",
       " ArrowRow({'sepal.length': 4.7,\n",
       "           'sepal.width': 3.2,\n",
       "           'petal.length': 1.3,\n",
       "           'petal.width': 0.2,\n",
       "           'variety': 'Setosa'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 15:46:58,458\tWARNING read_api.py:326 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    }
   ],
   "source": [
    "# Create from Parquet.\n",
    "ds = ray.data.read_parquet(\"example://iris.parquet\")\n",
    "# Dataset(num_blocks=1, num_rows=150,\n",
    "#         schema={sepal.length: float64, sepal.width: float64,\n",
    "#                 petal.length: float64, petal.width: float64, variety: object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=1, num_rows=150, schema={sepal.length: double, sepal.width: double, petal.length: double, petal.width: double, variety: string})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArrowRow({'sepal.length': 5.1,\n",
       "           'sepal.width': 3.5,\n",
       "           'petal.length': 1.4,\n",
       "           'petal.width': 0.2,\n",
       "           'variety': 'Setosa'}),\n",
       " ArrowRow({'sepal.length': 4.9,\n",
       "           'sepal.width': 3.0,\n",
       "           'petal.length': 1.4,\n",
       "           'petal.width': 0.2,\n",
       "           'variety': 'Setosa'}),\n",
       " ArrowRow({'sepal.length': 4.7,\n",
       "           'sepal.width': 3.2,\n",
       "           'petal.length': 1.3,\n",
       "           'petal.width': 0.2,\n",
       "           'variety': 'Setosa'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset]: Run `pip install tqdm` to enable progress reporting.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "# Create 10 blocks for parallelism.\n",
    "ds = ds.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=10, num_rows=150, schema={sepal.length: double, sepal.width: double, petal.length: double, petal.width: double, variety: string})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with sepal.length < 5.5 and petal.length > 3.5.\n",
    "def transform_batch(df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    return df[(df[\"sepal.length\"] < 5.5) & (df[\"petal.length\"] > 3.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ds = ds.map_batches(transform_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=10, num_rows=3, schema={sepal.length: float64, sepal.width: float64, petal.length: float64, petal.width: float64, variety: object})\n"
     ]
    }
   ],
   "source": [
    "print(transformed_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sepal.length': 5.2, 'sepal.width': 2.7, 'petal.length': 3.9, 'petal.width': 1.4, 'variety': 'Versicolor'}\n",
      "{'sepal.length': 5.4, 'sepal.width': 3.0, 'petal.length': 4.5, 'petal.width': 1.5, 'variety': 'Versicolor'}\n",
      "{'sepal.length': 4.9, 'sepal.width': 2.5, 'petal.length': 4.5, 'petal.width': 1.7, 'variety': 'Virginica'}\n"
     ]
    }
   ],
   "source": [
    "transformed_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PandasRow({'sepal.length': 5.2,\n",
       "            'sepal.width': 2.7,\n",
       "            'petal.length': 3.9,\n",
       "            'petal.width': 1.4,\n",
       "            'variety': 'Versicolor'}),\n",
       " PandasRow({'sepal.length': 5.4,\n",
       "            'sepal.width': 3.0,\n",
       "            'petal.length': 4.5,\n",
       "            'petal.width': 1.5,\n",
       "            'variety': 'Versicolor'}),\n",
       " PandasRow({'sepal.length': 4.9,\n",
       "            'sepal.width': 2.5,\n",
       "            'petal.length': 4.5,\n",
       "            'petal.width': 1.7,\n",
       "            'variety': 'Virginica'})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_ds.take()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ray Train: Distributed Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "num_samples = 20\n",
    "input_size = 10\n",
    "layer_size = 15\n",
    "output_size = 5\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(layer_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layer2(self.relu(self.layer1(input)))\n",
    "\n",
    "# In this example we use a randomly generated dataset.\n",
    "input = torch.randn(num_samples, input_size)\n",
    "labels = torch.randn(num_samples, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_func():\n",
    "    num_epochs = 3\n",
    "    model = NeuralNetwork()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.8631597757339478\n",
      "epoch: 1, loss: 0.8453680276870728\n",
      "epoch: 2, loss: 0.829220712184906\n"
     ]
    }
   ],
   "source": [
    "train_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train\n",
    "\n",
    "def train_func_distributed():\n",
    "    num_epochs = 3\n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 16:04:00,779\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-01-03 16:04:14</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:12.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.1/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/10 CPUs, 0/0 GPUs, 0.0/10.88 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_2f8c3_00000</td><td>TERMINATED</td><td>127.0.0.1:1255</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1275)\u001b[0m 2023-01-03 16:04:10,885\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=4]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1275)\u001b[0m 2023-01-03 16:04:11,958\tINFO train_loop_utils.py:270 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1275)\u001b[0m 2023-01-03 16:04:11,959\tINFO train_loop_utils.py:330 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1275)\u001b[0m epoch: 0, loss: 0.9114844799041748\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1278)\u001b[0m epoch: 0, loss: 0.9114844799041748\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1277)\u001b[0m epoch: 0, loss: 0.9114844799041748\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1279)\u001b[0m epoch: 0, loss: 0.9114844799041748\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1279)\u001b[0m epoch: 1, loss: 0.8945875763893127\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1275)\u001b[0m epoch: 1, loss: 0.8945875763893127\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1278)\u001b[0m epoch: 1, loss: 0.8945875763893127\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1277)\u001b[0m epoch: 1, loss: 0.8945875763893127\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1279)\u001b[0m epoch: 2, loss: 0.8796463012695312\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1275)\u001b[0m epoch: 2, loss: 0.8796463012695312\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1278)\u001b[0m epoch: 2, loss: 0.8796463012695312\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1277)\u001b[0m epoch: 2, loss: 0.8796463012695312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 16:04:14,943\tERROR checkpoint_manager.py:327 -- Result dict has no key: training_iteration. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['trial_id', 'experiment_id', 'date', 'timestamp', 'pid', 'hostname', 'node_ip', 'done']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial TorchTrainer_2f8c3_00000 completed. Last result: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 16:04:15,063\tINFO tune.py:762 -- Total run time: 12.53 seconds (12.40 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "# For GPU Training, set `use_gpu` to True.\n",
    "use_gpu = False\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_func_distributed,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=4, use_gpu=use_gpu)\n",
    ")\n",
    "\n",
    "results = trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "90b3346a2798b0e63493065519757b5aec3a8693cbbc5308e540adf640df9430"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
